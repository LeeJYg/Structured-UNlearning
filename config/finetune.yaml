model_family: llama2-7b

batch_size: 4
gradient_accumulation_steps: 4
num_epochs: 20
lr: 1e-5
save_dir: /home/jylee/SUN/finetuned_model/retrained_model/ft_epoch${num_epochs}_lr${lr}_wd${weight_decay}

weight_decay: 0.01
seed: 42